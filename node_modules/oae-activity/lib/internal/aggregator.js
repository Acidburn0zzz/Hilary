/*!
 * Copyright 2012 Sakai Foundation (SF) Licensed under the
 * Educational Community License, Version 2.0 (the "License"); you may
 * not use this file except in compliance with the License. You may
 * obtain a copy of the License at
 *
 *     http://www.osedu.org/licenses/ECL-2.0
 *
 * Unless required by applicable law or agreed to in writing,
 * software distributed under the License is distributed on an "AS IS"
 * BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express
 * or implied. See the License for the specific language governing
 * permissions and limitations under the License.
 */
var _ = require('underscore');
var log = require('oae-logger').logger('oae-activity-aggregator');
var Telemetry = require('oae-telemetry').telemetry('activity');
var util = require('util');

var Activity = require('oae-activity/lib/model').Activity;
var ActivityCluster = require('./cluster');
var ActivityConfig = require('./config');
var ActivityConstants = require('oae-activity/lib/constants').ActivityConstants;
var ActivityDAO = require('./dao');
var ActivityEntity = require('oae-activity/lib/model').ActivityEntity;

var ENTITY_KEY_EMPTY = '__null__';

var activityTypes = {};
var currentConcurrentCollectionCount = 0;

/**
 * Register special activity behaviour.
 *
 * @see ActivityAPI#registerActivityType
 */
var registerActivityType = module.exports.registerActivityType = function(activityType, options) {
    if (activityTypes[activityType]) {
        throw new Error('Attempted to register duplicate activity type');
    }
    activityTypes[activityType] = options;
};

/**
 * Perform a full collection of all activity buckets. If any bucket is already locked by another process, it will be skipped. When
 * this process completes and the callback is invoked, it will guarantee that:
 *
 * a) This process was not allowed to start another collection cycle, as there were too many occuring; or
 * b) for every bucket that wasn't locked, it was collected until it was empty.
 *
 * This is most useful for unit tests to ensure that all activities up until a point in time have been aggregated and delivered.
 *
 * @param   {Function}  [callback]  Invoked when collection is complete.
 */
var collectAllBuckets = module.exports.collectAllBuckets = function(callback) {
    callback = callback || function(err) {
        if (err) {
            log().error({'err': err}, 'Error collecting aggregates.');
        }
    };

    // Ensure we don't surpass the configured number of concurrent collections
    if (currentConcurrentCollectionCount >= ActivityConfig.getConfig().maxConcurrentCollections) {
        log().trace('Aborting collection due to max concurrent collections count reached.');
        return callback();
    }
    currentConcurrentCollectionCount++;

    // Fill all the possible bucket numbers to collect
    var bucketNumbers = [];
    for (var i = 0; i < ActivityConfig.getConfig().numberOfProcessingBuckets; i++) {
        bucketNumbers.push(i);
    }

    log().trace('Beginning collection of %s buckets.', bucketNumbers.length);

    // Perform a collection cycle on the bucket numbers
    collectBuckets(bucketNumbers, function() {
        log().trace('Completed collection cycle.');

        // Mark that this collection cycle has completed, whether or not there was an error
        currentConcurrentCollectionCount--;
        return callback();
    });
};

/**
 * Collects the given array of bucket numbers until they are empty, or "stolen". This process will skip over buckets that are
 * in the process of being collected. Therefore, if all buckets in the array are currently undergoing collection, this will not
 * actually perform any collections.
 *
 * @param   {Number[]}      bucketNumbers   The buckets that should be collected by this cycle.
 * @param   {Function}      callback        Invoked when the collection cycle completes.
 */
var collectBuckets = module.exports.collectBuckets = function(bucketNumbers, callback) {
    if (!bucketNumbers || bucketNumbers.length === 0) {
        return callback();
    }

    var bucketNumber = bucketNumbers.shift();
    _collectBucket(bucketNumber, function(err) {
        if (err) {
            log().warn({'err': err, 'bucketNumber': bucketNumber}, 'Error collecting aggregate bucket.');
            Telemetry.incr('collection.error.count');
        }

        collectBuckets(bucketNumbers, callback);
    });
};

/**
 * Collect the provided bucket number until it is empty (or "stolen"). If the bucket is already being collected, this will
 * effectively do nothing.
 *
 * @param   {Number}    bucketNumber        The number of the bucket to collect.
 * @param   {Function}  callback            Invoked when collection is complete.
 * @param   {Object}    callback.err        An error that occurred, if any.
 * @api private
 */
var _collectBucket = function(bucketNumber, callback) {
    log().trace('Attempting collection of bucket number %s', bucketNumber);
    // Try and acquire a lock on the bucket to collect the next batch
    ActivityCluster.acquireBucket(bucketNumber, ActivityConfig.getConfig().collectionExpiry, function(err, lockId) {
        if (err) {
            return callback(err);
        } else if (lockId) {
            // We acquired the lock, perform a collection iteration
            _collectBucketBatch(bucketNumber, ActivityConfig.getConfig().collectionBatchSize, function(collectionErr, empty) {
                // We want to ensure we release the bucket, whether we received an error or not
                ActivityCluster.releaseBucket(bucketNumber, lockId, function(releaseErr) {
                    if (collectionErr) {
                        return callback(collectionErr);
                    } else if (releaseErr) {
                        // If there was an error releasing the lock, worst case scenario would be that the lock eventually expires
                        // and a cluster node picks it up soon after that and continues processing.
                        return callback(releaseErr);
                    } else if (empty) {
                        // The bucket is now empty, return to the caller
                        return callback();
                    }

                    // The bucket isn't empty, try another collection iteration
                    return _collectBucket(bucketNumber, callback);
                });
            });
        } else {
            // We could not acquire a lock, someone else came around and managed to snag the bucket
            return callback();
        }
    });
};

/**
 * Collect and process a certain amount of routed activities from the given bucket. This method is *not safe* in the sense
 * that it does not try and first acquire a lock on the bucket. Do not use this directly, instead use `collectBucket` which
 * in turn uses this method with locks.
 *
 * @param   {Number}    bucketNumber        The bucket to process.
 * @param   {Number}    limit               The number of routed activities to collect, process and deliver.
 * @param   {Function}  callback            Invoked when the batch has been processed.
 * @param   {Object}    callback.err        An error that occurred, if any.
 * @api private
 */
var _collectBucketBatch = function(bucketNumber, limit, callback) {
    var collectionStart = Date.now();
    log().trace('Collecting batch of %s entries from bucket number %s.', limit, bucketNumber);

    // Get the next batch of queued activities to process
    ActivityDAO.getQueuedActivities(bucketNumber, limit, function(err, routedActivities) {
        if (err) {
            return callback(err);
        }

        // These routed activities will be deleted by the internal id after they've been processed
        var queuedActivitiesToDelete = _.keys(routedActivities);
        var numCollected = queuedActivitiesToDelete.length;
        if (numCollected === 0) {
            // No more to process, so stop and report that we're empty.
            return callback(null, true);
        }

        // Explode the routed activities into their potential aggregates, according to their configured pivot points
        var allAggregates = _createAggregates(_.values(routedActivities));
        var allAggregateKeys = _.keys(allAggregates);

        // Get all aggregate statuses to determine which ones are expired and which are active
        // Expired aggregates should be deleted, while active aggregates should be merged and redelivered
        ActivityDAO.getAggregateStatus(allAggregateKeys, function(err, statusByAggregateKey) {
            if (err) {
                return callback(err);
            }

            // Figure out which aggregates are "active" (have an activity in its aggregate) and "expired" (no new activities in the aggregate before expiry time)
            var activeAggregates = {};
            var expiredAggregates = {};
            allAggregateKeys.forEach(function(aggregateKey) {
                var aggregate = allAggregates[aggregateKey];
                var status = statusByAggregateKey[aggregateKey];
                if (status && _isExpired(status, allAggregates[aggregateKey].published)) {
                    expiredAggregates[aggregateKey] = true;
                } else if (status) {
                    activeAggregates[aggregateKey] = true;
                }
            });

            // Note: We need to delete aggregated entities and save them here within the collection chain to avoid nuking undelivered
            // entities. If we saved aggregated entities during the routing phase and only deleted them here, it would save us a write
            // as we wouldn't have to write them to the queue, but it exposes a race condition where entities that are saved between
            // getAggregateStatus (above) and deleteAggregatedEntities (below) will be deleted before delivery.

            // Delete all the expired aggregates before aggregating new stuff
            ActivityDAO.deleteAggregates(_.keys(expiredAggregates), function(err) {
                if (err) {
                    return callback(err);
                }

                // Retrieve all entities that are aggregated within the live aggregates so they can be collected into redelivered activities
                ActivityDAO.getAggregatedEntities(_.keys(activeAggregates), function(err, fetchedEntities) {
                    if (err) {
                        return callback(err);
                    }

                    /*!
                     * Here we choose which aggregates need to be wrapped up into an activity and delivered to the activity stream. This is
                     * rather difficult to get right. These are the rules implemented below:
                     *
                     *  For a given activity:
                     *
                     * 1.   If an aggregate was previously active for it, it will always be re-delivered to that aggregate stream. If there
                     *      was a previous activity delivered for the aggregate in that stream, that activity is deleted from the stream.
                     *
                     * 2.   If there are multiple active aggregates for the activity in the stream, all should be delivered as they all have
                     *      been updated. This means that if an activity has multiple aggregates, you could update the branched activities
                     *      for *both* aggregates (e.g., content-share). "Branching" means that 2 separate aggregations have started and are
                     *      tracking two separate activities in a feed.
                     *
                     *      How can an activity fall into two branches? Using content-share as an example, let's say we have 2 live
                     *      aggregates:
                     *
                     *          Aggregate #1: "Branden shared 5 content items with OAE Team"
                     *          Aggregate #2: "Branden shared Syllabus with 5 Users and Groups"
                     *
                     *      Now, if Branden decides to share "Syllabus" with "OAE Team", you have matched both of these aggregates, and both
                     *      "branches" will be updated and moved to the top of the feed.
                     *
                     * 3.   An activity is only delivered for an inactive aggregate if the activity was not "claimed" for the route by an
                     *      active aggregate. This would make sure that we don't update a live aggregate, AND deliver the single activity
                     *      (e.g., "Branden shared Syllabus with OAE Team") in the same route.
                     *
                     * 4.   If no active aggregates claim an activity, and there are multiple inactive aggregates (e.g., the activity type has
                     *      multiple "pivot points"), then one single activity is delivered for all of them. This is necessary to ensure that
                     *      the "lastActivityId" is recorded properly for both aggregates, so if either of those inactive aggregates become
                     *      active later (i.e., another activity comes along and matches it), the previous activity can be properly deleted by
                     *      either of the aggregates.
                     *
                     * 5.   If an activity gets "duplicated", it should not result in multiple activities, it should instead just update the
                     *      publish date and the content entities of the original activities.
                     */

                    // Mark all active aggregates to be delivered and create a new activity ID for them, as they will "branch" into
                    // their activity.
                    var aggregatesToDeliver = {};
                    var activitiesToDelete = {};
                    var claimedRouteActivities = {};
                    allAggregateKeys.forEach(function(aggregateKey) {
                        var aggregate = allAggregates[aggregateKey];
                        if (activeAggregates[aggregateKey] || aggregate.activityIds.length > 1) {
                            var status = statusByAggregateKey[aggregateKey];
                            
                            // Mark this to be delivered and assign it an activity id
                            aggregatesToDeliver[aggregateKey] = true;
                            aggregate[ActivityConstants.properties.OAE_ACTIVITY_ID] = ActivityDAO.createActivityId(aggregate.published);

                            // Mark these activities for this route as being claimed by an active aggregate
                            claimedRouteActivities[aggregate.route] = claimedRouteActivities[aggregate.route] || {};
                            aggregate.activityIds.forEach(function(activityId) {
                                claimedRouteActivities[aggregate.route][activityId] = true;
                            });

                            // If this was previously delivered, delete the previous activity
                            if (status && status.lastActivity) {
                                activitiesToDelete[aggregate.route] = activitiesToDelete[aggregate.route] || {};
                                activitiesToDelete[aggregate.route][status.lastActivity] = true;
                            }
                        }
                    });

                    // Second, for aggregates that are not active, determine if they can be delivered
                    allAggregateKeys.forEach(function(aggregateKey) {
                        var aggregate = allAggregates[aggregateKey];
                        // Any aggregate that had more than 1 activityId was claimed as active. We can safely just use the first
                        // activityId to get the activityId that represents this aggregate
                        var activityId = aggregate.activityIds[0];
                        var isActivityClaimed = (claimedRouteActivities[aggregate.route] && claimedRouteActivities[aggregate.route][activityId]);
                        if (!activeAggregates[aggregateKey] && !isActivityClaimed) {
                            // If this route has not received an aggregate, then we deliver the non-active one(s). In the event that
                            // there are multiple non-active aggregates, a duplicate activity will not be fired because we flatten and
                            // maintain a set while generating activities later.
                            aggregatesToDeliver[aggregateKey] = true;
                            aggregate[ActivityConstants.properties.OAE_ACTIVITY_ID] = activityId;
                        }
                    });

                    // Save the aggregated entities stored in the current batch of aggregates
                    ActivityDAO.saveAggregatedEntities(allAggregates, function(err) {
                        if (err) {
                            return callback(err);
                        }

                        // Create the actual activities to route
                        var visitedActivities = {};
                        var activityStreamUpdates = {};
                        _.keys(aggregatesToDeliver).forEach(function(aggregateKey) {
                            var aggregate = allAggregates[aggregateKey];

                            // Construct the activities to deliver
                            var activityType = aggregate[ActivityConstants.properties.OAE_ACTIVITY_TYPE];
                            var verb = aggregate.verb;
                            var published = aggregate.published;
                            var actors = aggregate.actors;
                            var objects = aggregate.objects;
                            var targets = aggregate.targets;

                            // Refresh the entities with the freshly fetched set, which has all the entities, not those just in this collection
                            // We need to make sure we override with the queued entities and not the freshly fetched ones since they may have been
                            // updated since original aggregation.
                            if (fetchedEntities[aggregateKey]) {
                                actors = _.extend(fetchedEntities[aggregateKey].actors, actors);
                                objects = _.extend(fetchedEntities[aggregateKey].objects, objects);
                                targets = _.extend(fetchedEntities[aggregateKey].targets, targets);
                            }

                            // Make sure that we don't deliver an identical activity to the same stream twice. This can potentially
                            // happen when an activity type has multiple pivots that were inactive prior to this activity (e.g., content-share)
                            var activityId = null;
                            var flattenedActivity = _flattenActivity(aggregate);
                            if (visitedActivities[flattenedActivity]) {
                                // We assign the previous activity id to the aggregate so that we can update the aggregate status to know that
                                // any new activities for this aggregate should replace its existing activity
                                aggregate[ActivityConstants.properties.OAE_ACTIVITY_ID] = visitedActivities[flattenedActivity];
                                return;
                            } else {
                                // This activity is not a duplicate, assign and record a new activityId
                                activityId = ActivityDAO.createActivityId(aggregate.published);
                                aggregate[ActivityConstants.properties.OAE_ACTIVITY_ID] = activityId;
                                visitedActivities[flattenedActivity] = activityId;
                            }

                            // Create the entities for the delivered activity
                            var actor = _createActivityEntity(_.values(actors));
                            var object = _createActivityEntity(_.values(objects));
                            var target = _createActivityEntity(_.values(targets));

                            activityStreamUpdates[aggregate.route] = activityStreamUpdates[aggregate.route] || {};
                            activityStreamUpdates[aggregate.route][activityId] = new Activity(activityType, activityId, verb, published, actor, object, target);
                        });

                        // Deliver the new activities to the streams
                        ActivityDAO.deliverActivities(activityStreamUpdates, function(err) {
                            if (err) {
                                return callback(err);
                            }

                            // Collection date is marked as the date/time that the aggregate gets delivered
                            var collectionDate = Date.now();

                            // Record how long it took for these to be delivered
                            _.keys(activityStreamUpdates).forEach(function(route) {
                                _.keys(activityStreamUpdates[route]).forEach(function(activityId) {
                                    var activity = activityStreamUpdates[route][activityId];
                                    Telemetry.appendDuration('activity.queue.time', activity.published);
                                });
                            });

                            // The activitiesToDelete hash values should actually be arrays of unique activity ids, not "<activity id>: true" pairs.
                            _.keys(activitiesToDelete).forEach(function(route) {
                                activitiesToDelete[route] = _.keys(activitiesToDelete[route]);
                            });

                            // Delete the old activities that were replaced by aggregates
                            ActivityDAO.deleteActivities(activitiesToDelete, function(err) {
                                if (err) {
                                    return callback(err);
                                }

                                // Determine how to update all the aggregate statuses
                                var statusUpdates = {};
                                allAggregateKeys.forEach(function(aggregateKey) {
                                    var aggregate = allAggregates[aggregateKey];
                                    statusUpdates[aggregateKey] = {
                                        'lastUpdated': aggregate.published,
                                        'lastCollected': collectionDate
                                    };

                                    if (!activeAggregates[aggregateKey]) {
                                        // This aggregate was not previously active, so mark its creation date at the beginning of the first activity
                                        statusUpdates[aggregateKey].created = aggregate.published;
                                    }

                                    // Mark the last activity for each aggregate. This ensures that when a new activity gets added to the aggregate, we can
                                    // delete the previous one.
                                    if (aggregate[ActivityConstants.properties.OAE_ACTIVITY_ID]) {
                                        statusUpdates[aggregateKey].lastActivity = aggregate[ActivityConstants.properties.OAE_ACTIVITY_ID];
                                    }
                                });

                                // Update the activity statuses, indicating they have just been updated and collected, where applicable
                                ActivityDAO.updateAggregateStatus(statusUpdates, function(err) {
                                    if (err) {
                                        return callback(err);
                                    }

                                    // Remove the queued routed activities that were just delivered / aggregated so they don't get re-processed
                                    ActivityDAO.deleteQueuedActivities(bucketNumber, queuedActivitiesToDelete, function(err) {
                                        if (err) {
                                            return callback(err);
                                        }

                                        // activitiesCollected marks the number of activities collected, and how long it took
                                        Telemetry.incr('collection.count');
                                        Telemetry.appendDuration('collection.time', collectionStart);
                                        Telemetry.append('activitiesCollected.count', numCollected);

                                        return callback();
                                    });
                                });
                            });
                        });
                    });
                });
            });
        });
    });
};


/**
 * Explode the given routed activities into all potential aggregates. An aggregate is a permutation of a routed activity that
 * further keys each by the pivot points by which the activity can be aggregated over a period of time.
 *
 * The routed activities are an array of following form:
 *
 * [
 *  {
 *      'route': <route>,
 *      'activity': <Activity>
 *  },
 *  { ... }
 * ]
 *
 * Where the route specifies the route to which the activity should be delivered, and the activity is the activity to deliver.
 *
 * The result will be an object representing the aggregation of all the routed activities in the list, keyed by the aggregate key. An
 * example aggregation of an activity that pivots on actor and had 3 matching aggregates in the array would be:
 *
 *  {
 *       '<aggregateKey>': {
 *           'route': '...',
 *           'numberOfActivities': 3,
 *           'oae:activityType': '...',
 *           'activityIds': {
 *              '<activityId0>': true,
 *              ...
 *           },
 *           'verb': '...',
 *           'published': '...',
 *           'actors': {
 *               '<actorKey0>': <ActivityEntity (actor)>
 *           },
 *           'objects': {
 *               '<objectKey0>': <ActivityEntity (object)>,
 *               '<objectKey1>': <ActivityEntity (object)>,
 *               '<objectKey2>': <ActivityEntity (object)>
 *           },
 *           'targets': {}
 *       }
 *  }
 *
 * @param   {Object[]}  routedActivities    An array of activities along with the route to which they should be delivered. See summary for more information.
 * @return  {Object}                        An object representing the potential aggregates of the collected batch of activities.
 * @api private
 */
var _createAggregates = function(routedActivities) {
    var aggregates = {};
    routedActivities.forEach(function(routedActivity) {
        var route = routedActivity.route;
        var activity = routedActivity.activity;
        var activityType = activity[ActivityConstants.properties.OAE_ACTIVITY_TYPE];
        var activityId = activity[ActivityConstants.properties.OAE_ACTIVITY_ID];

        // Build the entity keys which will be used to create the aggregate key
        var actorKey = _createEntityKey(activity.actor);
        var objectKey = _createEntityKey(activity.object);
        var targetKey = _createEntityKey(activity.target);

        // Determine how this activity will be grouped (a.k.a., pivot points) for aggregation
        var groupBy = (activityTypes[activityType]) ? activityTypes[activityType].groupBy : [];

        // Ensure we atleast have the "all" aggregate, which means we don't get duplicate activities within the same aggregation
        // period.
        if (groupBy.length === 0) {
            groupBy = [{
                'actor': true,
                'object': true,
                'target': true
            }];
        }

        // For each potential grouping, create an "aggregate key", which will be used to determine if new activity deliveries
        // match with the same key.
        groupBy.forEach(function(pivot) {
            var pivotActorKey = (pivot.actor) ? actorKey : '';
            var pivotObjectKey = (pivot.object) ? objectKey : '';
            var pivotTargetKey = (pivot.target) ? targetKey : '';
            var aggregateKey = util.format('%s#%s#%s#%s#%s', activityType, route, pivotActorKey, pivotObjectKey, pivotTargetKey);

            // This process of collecting actors, objects, targets and activities is in some respect "in-memory aggregation". It
            // helps to use this to determine ahead of time if there are a few activities within this batch of routed activities
            // that already match. It helps us deliver an aggregate right away to the route, rather than accidentally delivering
            // individual activities from within a batch.
            if (!aggregates[aggregateKey]) {
                aggregates[aggregateKey] = {
                    'route': route,
                    'activityIds': [],
                    'verb': activity.verb,
                    'published': activity.published,
                    'actors': {},
                    'objects': {},
                    'targets': {}
                };
                aggregates[aggregateKey][ActivityConstants.properties.OAE_ACTIVITY_TYPE] = activityType;
            }

            var aggregate = aggregates[aggregateKey];
            var suppressAggregate = true;

            // Below, we suppress the aggregate only if it does not contribute any new entity to an existing aggregate. This
            // allows us to avoid aggregating exact duplicates from within the batch and making it look like it is a live
            // aggregate.

            if (activity.actor && !aggregate.actors[actorKey]) {
                suppressAggregate = false;
                aggregate.actors[actorKey] = activity.actor;
            }

            if (activity.object) {
                suppressAggregate = false;
                aggregate.objects[objectKey] = activity.object;
            }

            if (activity.target) {
                suppressAggregate = false;
                aggregate.targets[targetKey] = activity.target;
            }

            if (!suppressAggregate) {
                aggregate.published = activity.published;
                aggregate.activityIds.push(activity[ActivityConstants.properties.OAE_ACTIVITY_ID]);
            }
        });
    });

    return aggregates;
};

/**
 * Given an array of activity entities, return a new top-level activity entity representing how it should be modeled in an activity
 * stream.
 *
 * @param   {ActivityEntity[]}  entities        The activity entities to transform.
 * @return  {ActivityEntity}                    An individual activity entity that represents the collection of entities.
 * @api private
 */
var _createActivityEntity = function(entities) {
    if (!entities) {
        return undefined;
    } else if (!entities.length) {
        return undefined;
    } else if (entities.length === 1) {
        return entities[0];
    }

    var ext = {};
    ext[ActivityConstants.properties.OAE_COLLECTION] = entities;
    return new ActivityEntity('collection', undefined, {'ext': ext});
};

/**
 * Flatten an aggregate into a string identity that allows us to determine if the activity that will be created by an aggregate
 * is identical to another. This can be used to maintain a hash of identities to quick determine whether or not an activity
 * should be delivered.
 *
 * @param   {Object}    aggregate   The aggregate from which to deliver an activity identity
 * @return  {String}                A string identity that can be used to determine if one activity is identical to another
 * @api private
 */
var _flattenActivity = function(aggregate) {
    var route = aggregate.route;
    var activityType = aggregate[ActivityConstants.properties.OAE_ACTIVITY_TYPE];

    // Create a multi-key of all the actors, objects and targets so they are deterministic
    var actorsKeys = [];
    _.values(aggregate.actors).forEach(function(actor) {
        actorsKeys.push(_createEntityKey(actor));
    });
    actorsKeys = actorsKeys.sort().join(',');

    var objectsKeys = [];
    _.values(aggregate.objects).forEach(function(object) {
        objectsKeys.push(_createEntityKey(object));
    });
    objectsKeys = objectsKeys.sort().join(',');

    var targetsKeys = [];
    _.values(aggregate.targets).forEach(function(target) {
        targetsKeys.push(_createEntityKey(target));
    });
    targetsKeys = targetsKeys.sort().join(',');

    // Generate the identity key for the activity described by the aggregate
    return util.format('%s#%s#%s#%s#%s', activityType, route, actorsKeys, objectsKeys, targetsKeys);
};

/**
 * Create a unique string representation from the given entity. If the entity is not specified, returns `ENTITY_KEY_EMPTY`
 * as a placeholder for the entity key.
 *
 * @param   {ActivityEntity}    entity      The entity for which to create an entity key.
 * @return  {String}                        A unique string representation of the entity.
 */
var _createEntityKey = function(entity) {
    return (entity) ? util.format('%s:%s', entity.objectType, entity[ActivityConstants.properties.OAE_ID]) : ENTITY_KEY_EMPTY;
};

/**
 * Determine if the aggregate described by aggregateStatus is considered to be expired at the provided published date.
 *
 * @param   {Object}    aggregateStatus         The aggregate status entry.
 * @param   {Number}    published               The published date (in millis since the epoch) that the next activity occurred.
 * @param   {Boolean}                           Whether or not the aggregate is expired.
 */
var _isExpired = function(aggregateStatus, published) {
    var lastUpdateWasCollected = (aggregateStatus.lastCollected && aggregateStatus.lastCollected > aggregateStatus.lastUpdated);
    var lastUpdateIsIdleExpired = ((published - aggregateStatus.lastUpdated) > ActivityConfig.getConfig().aggregateIdleExpiry);
    var createdMaxIsExpired = ((published - aggregateStatus.created) > ActivityConfig.getConfig().aggregateMaxExpiry);
    return (lastUpdateWasCollected && (lastUpdateIsIdleExpired || createdMaxIsExpired));
};

